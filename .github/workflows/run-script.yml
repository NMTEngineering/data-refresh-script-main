name: Scrape and Upload to Cloud

on:
  schedule:
    # Runs every Sunday at 09:58 UTC (adjust to your desired time)
    - cron: '58 9 * * 0'
  workflow_dispatch:  # Allow manual trigger

jobs:
  scrape_and_upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        # Assuming you have requirements.txt containing: selenium, beautifulsoup4
        run: pip install -r requirements.txt

      - name: Run Scraping Script
        run: python yellowpages_hammer_unions.py

      # ----------------------------------------------------------------------
      # Step to Upload to Google Drive (Recommended Easiest Cloud Integration)
      # ----------------------------------------------------------------------
      - name: Upload CSV to Google Drive
        # FIX: Switched to the widely used and reliable 'gautamkrishnar/upload-google-drive@v2' action
        uses: gautamkrishnar/upload-google-drive@v2
        with:
          # The entire JSON content of your Service Account Key
          client_json: ${{ secrets.GDRIVE_SERVICE_ACCOUNT_CREDENTIALS }}
          
          # The path to the file generated by the Python script
          file: yellowpages_hammer_unions.csv
          
          # IMPORTANT: This must be the unique folder ID (the string *after* /folders/)
          folder_id: 13D4zIg4-kHcAVDL_XS_Ry1uABYkrLYmJ
          
          # Optional: Use dynamic filename with date/time
          # Note: The new action uses 'upload_file_name' for this purpose
          upload_file_name: hammer_unions_scrape_${{ github.event.release.tag_name || github.run_number }}.csv
          
          # Set to true to overwrite the file if it exists (highly recommended for daily/weekly reports)
          # Note: The new action uses 'overwrite'
          overwrite: true
          
      # ----------------------------------------------------------------------
      # Optional: Keep GitHub Artifact for troubleshooting (as you had before)
      # ----------------------------------------------------------------------
      - name: Upload Artifact to GitHub
        uses: actions/upload-artifact@v4
        with:
          name: scrape-output-csv
          path: "*.csv"
